{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4fca17-fd26-4760-9434-fda000bf83fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "chdir('C:/Users/samue/Documents/GitHub/GAN_Scripts')\n",
    "\n",
    "from GAN_Tools import get_default_device, to_device, GanComponent, Results, Environment\n",
    "from GAN_Tools import classification_metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import mkdir\n",
    "from os.path import isdir, exists\n",
    "from torch import optim\n",
    "import random\n",
    "from torch import manual_seed\n",
    "from plotnine import ggplot, aes, geom_line, geom_vline, labels, scales\n",
    "import joblib\n",
    "import yaml\n",
    "\n",
    "with open(\"./microarray_config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad983db2-95d2-487b-a082-8d082b310f7f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 1 out of 3: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 3.7084922790527344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 2 out of 3: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 5.813468933105469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 3 out of 3:  60%|████████████████████████████████████████▏                          | 3/5 [00:31<00:21, 10.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 3.9631497859954834\n",
      "lr_2 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:37<00:00, 13.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:11<00:00, 13.97it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/1e-05 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 0.5043535693999259, -0.02032921314239511\n",
      "lr_2 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:35<00:00, 14.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:14<00:00, 13.41it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/5e-05 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 0.5176735539590159, 0.12695631980896005\n",
      "lr_2 3 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:36<00:00, 13.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:12<00:00, 13.76it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/0.0001 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 0.5724144393000109, 0.33358523368835424\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:38<00:00, 12.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 9500/9500 [11:21<00:00, 13.95it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py:906: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/plot_loss_bestFit_loop_1Pretraining.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 172, epoch 3440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/plot_loss_loop_1Pretraining.png\n",
      "lr_1 1 out of 3:  40%|██████████████████████████▊                                        | 2/5 [00:22<00:33, 11.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 3.289930820465088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 2 out of 3: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:37<00:00,  7.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 7.368011474609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 3 out of 3:  20%|█████████████▍                                                     | 1/5 [00:14<00:59, 14.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 3.632535696029663\n",
      "lr_2 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [00:19<00:00, 13.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:16<00:00, 13.15it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/1e-05 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 1.1315669167426325, 0.2719572973251343\n",
      "lr_2 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [00:19<00:00, 13.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:15<00:00, 13.29it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/5e-05 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 1.497876208404015, 1.5006061315536499\n",
      "lr_2 3 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [00:19<00:00, 13.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:15<00:00, 13.26it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/0.0001 tuning_loss_retrain.png\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\geoms\\geom_path.py:75: PlotnineWarning: geom_path: Removed 1 rows containing missing values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 41\n",
      "Final instab and diff: 1.6623551959083194, 2.0342165353821544\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 260/260 [00:19<00:00, 13.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 9740/9740 [11:59<00:00, 13.53it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py:906: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/plot_loss_bestFit_loop_2Pretraining.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 54, epoch 1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/plot_loss_loop_2Pretraining.png\n",
      "lr_1 1 out of 3: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 7.8259477615356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 2 out of 3: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 10.369722366333008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lr_1 3 out of 3:  60%|████████████████████████████████████████▏                          | 3/5 [00:11<00:07,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss reached: 5.16210412979126\n",
      "lr_2 1 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:09<00:00, 35.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:30<00:00, 32.29it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/1e-05 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 1.398572830053476, 0.018340291976928214\n",
      "lr_2 2 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:09<00:00, 34.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:28<00:00, 34.89it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/5e-05 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 1.513040331693796, 0.38995864391326895\n",
      "lr_2 3 out of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:09<00:00, 34.83it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:28<00:00, 35.03it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/0.0001 tuning_loss_retrain.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 50\n",
      "Final instab and diff: 1.660240127490117, 0.953804049491882\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 340/340 [00:09<00:00, 34.56it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 9660/9660 [04:36<00:00, 34.95it/s]\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py:906: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/plot_loss_bestFit_loop_3Pretraining.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value at index 80, epoch 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:718: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "C:\\Users\\samue\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\plotnine\\ggplot.py:719: PlotnineWarning: Filename: ./Results/External_Results/plot_loss_loop_3Pretraining.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(3, 2, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 156\u001b[0m\n\u001b[0;32m    153\u001b[0m telapsed_summary_3 \u001b[38;5;241m=\u001b[39m Env_pre\u001b[38;5;241m.\u001b[39mtuneAndTrain(max_loss, min_loss, dropout_prob, preTrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m##Save time stats\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m dat_telapsed \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtelapsed_summary_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtelapsed_summary_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtelapsed_summary_3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m dat_telapsed\u001b[38;5;241m.\u001b[39mto_csv(Env_pre\u001b[38;5;241m.\u001b[39mPATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Results/telapsed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\pandas\\core\\frame.py:762\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    754\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    755\u001b[0m             arrays,\n\u001b[0;32m    756\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    760\u001b[0m         )\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 762\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    772\u001b[0m         {},\n\u001b[0;32m    773\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    777\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\pandas\\core\\internals\\construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    324\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_prep_ndarraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_on_sanitize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dtype_equal(values\u001b[38;5;241m.\u001b[39mdtype, dtype):\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;66;03m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     rcf \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\synthMeats\\lib\\site-packages\\pandas\\core\\internals\\construction.py:583\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    581\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(3, 2, 1)"
     ]
    }
   ],
   "source": [
    "config_pre = config[\"pretraining\"]\n",
    "\n",
    "PATH = config[\"PATH\"]\n",
    "\n",
    "##Check dir structure, and make sub-directories if not present\n",
    "if not isdir(PATH+'/Results'):\n",
    "    mkdir(PATH+'/Results')\n",
    "if not isdir(PATH+'/Results/External_Results'):\n",
    "    mkdir(PATH+'/Results/External_Results')\n",
    "if not isdir(PATH+'/Results/Main_Results'):\n",
    "    mkdir(PATH+'/Results/Main_Results')\n",
    "if not isdir(PATH+'/Results/External_Results/Saved_Pars'):\n",
    "    mkdir(PATH+'/Results/External_Results/Saved_Pars')\n",
    "if not isdir(PATH+'/Results/Main_Results/Saved_Pars'):\n",
    "    mkdir(PATH+'/Results/Main_Results/Saved_Pars')\n",
    "if not isdir(PATH+'/Results/Main_Results/overrep'):\n",
    "    mkdir(PATH+'/Results/Main_Results/overrep')\n",
    "if not isdir(PATH+'/Results/Main_Results/overrep/Saved_Pars'):\n",
    "    mkdir(PATH+'/Results/Main_Results/overrep/Saved_Pars')\n",
    "if not isdir(PATH+'/Data'):\n",
    "    mkdir(PATH+'/Data')\n",
    "    print('WARNING: ENSURE DATA IS COPIED INTO THIS DIRECTORY')\n",
    "\n",
    "\n",
    "Env_pre = Environment()\n",
    "Env_pre.device = get_default_device()\n",
    "\n",
    "experiment_data = config[\"experiment_data\"]\n",
    "\n",
    "Env_pre.PATH = PATH\n",
    "\n",
    "Env_pre.tune_params = dict(\n",
    "    max_epochs_1=config_pre[\"max_epochs_1\"], \n",
    "    max_loss_1=config_pre[\"max_loss_1\"], \n",
    "    n_epochs_2=config_pre[\"n_epochs_2\"], \n",
    "    dropout_prob=config_pre[\"dropout_prob\"], \n",
    "    seed=config_pre[\"random_seed\"], \n",
    "    lr_1 = config_pre[\"lr_1\"],\n",
    "    lr_2 = config_pre[\"lr_2\"],              \n",
    "    rate_save = config_pre[\"rate_save\"], \n",
    "    diff_epochs = config_pre[\"diff_epochs\"], \n",
    "    max_loss_2 = config_pre[\"max_loss_2\"], \n",
    "    min_loss_2 = config_pre[\"min_loss_2\"],\n",
    "    alpha_instab = config_pre[\"alpha_instab\"],\n",
    ")\n",
    "    \n",
    "np.random.seed(config[\"random_seed\"])\n",
    "manual_seed(config[\"random_seed\"])\n",
    "random.seed(config[\"random_seed\"])\n",
    "\n",
    "#%%\n",
    "###TRAINING\n",
    "#pars\n",
    "Env_pre.func_optim = getattr(optim, config_pre[\"func_optim\"])\n",
    "Env_pre.n_features = config_pre[\"n_features\"]\n",
    "Env_pre.alpha = config_pre[\"alpha\"]\n",
    "Env_pre.beta = config_pre[\"beta\"]\n",
    "Env_pre.batch_size = config_pre[\"batch_size\"]\n",
    "Env_pre.iter_critic = config_pre[\"iter_critic\"]\n",
    "\n",
    "dropout_prob = config_pre[\"dropout_prob\"]\n",
    "\n",
    "#%%\n",
    "##remove IDs if real data\n",
    "def prepare_dat(path_dir, file_name, n_cols_rem):\n",
    "    if not exists(path_dir + '/' + file_name[:-4] + '_inp.csv'):\n",
    "        dat_temp = pd.read_csv(path_dir + '/' + file_name)\n",
    "        dat_temp = dat_temp.iloc[:, n_cols_rem:]\n",
    "        dat_temp.to_csv(path_dir + '/' + file_name[:-4] + '_inp.csv', index = False)\n",
    "\n",
    "#remove ID and label\n",
    "prepare_dat(PATH + '/Data', 'dat_ext.csv', config_pre[\"data_prep\"][experiment_data])    \n",
    "     \n",
    "#%%\n",
    "##Train pre_GAN on external data\n",
    "\n",
    "#For sim\n",
    "#Env_pre.path_dat = PATH + '/sim_dat_ext.csv'\n",
    "#For real\n",
    "Env_pre.path_dat = PATH + '/Data/dat_ext_inp.csv'\n",
    "\n",
    "Env_pre.path_results = PATH + '/Results/External_Results'\n",
    "Env_pre.path_pars = Env_pre.path_results + '/Saved_Pars'\n",
    "\n",
    "gen_struct = config_pre[\"gen_structure\"]\n",
    "critic_struct = config_pre[\"critic_structure\"]\n",
    "\n",
    "Env_pre.n_training_samples = sum(1 for line in open(Env_pre.path_dat)) - 1 #number of records in file (excludes header)\n",
    "\n",
    "Env_pre.critic = GanComponent(Env_pre.n_features, \n",
    "                              Env_pre.init_weights, \n",
    "                              critic_struct[0], \n",
    "                              dropout_prob,\n",
    "                              \"critic\")\n",
    "Env_pre.generator = GanComponent(Env_pre.n_features, \n",
    "                                 Env_pre.init_weights, \n",
    "                                 gen_struct[0], \n",
    "                                 dropout_prob,\n",
    "                                 \"generator\")\n",
    "Env_pre.results_record = Results(path = Env_pre.path_results, saved_results = False)\n",
    "\n",
    "to_device(Env_pre.critic.train(), Env_pre.device)\n",
    "to_device(Env_pre.generator.train(), Env_pre.device)\n",
    "\n",
    "\n",
    "##transformer generated based on batch of size 200 or max data if < 200 (95 samples in metabolomics)\n",
    "if experiment_data == 'metabolomics':\n",
    "    Env_pre.transformer = Env_pre.get_scaler(95, '/ext_transformer.pkl')\n",
    "else:\n",
    "    Env_pre.transformer = Env_pre.get_scaler(200, '/ext_transformer.pkl')\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "##First training loop\n",
    "#if experiment_data == 'microarray':\n",
    "#    Env_pre.lr = 0.0005\n",
    "#    n_epochs = 1000\n",
    "#if experiment_data == 'simulation':\n",
    "#    Env_pre.lr = 0.001\n",
    "#    n_epochs = 1000\n",
    "#if experiment_data == 'metabolomics':\n",
    "#    Env_pre.lr = 0.001\n",
    "#    n_epochs = 1000\n",
    "\n",
    "##First training loop\n",
    "telapsed_summary_1 = Env_pre.tuneAndTrain(preTrained=False)\n",
    "\n",
    "Env_pre.generator.grow(gen_struct[1])\n",
    "Env_pre.critic.grow(critic_struct[1])\n",
    "\n",
    "to_device(Env_pre.generator, Env_pre.device)\n",
    "to_device(Env_pre.critic, Env_pre.device)\n",
    "\n",
    "##Second training loop\n",
    "telapsed_summary_2 = Env_pre.tuneAndTrain(preTrained=False)\n",
    "\n",
    "Env_pre.generator.grow(gen_struct[2])\n",
    "Env_pre.critic.grow(critic_struct[2])\n",
    "\n",
    "to_device(Env_pre.generator, Env_pre.device)\n",
    "to_device(Env_pre.critic, Env_pre.device)\n",
    "\n",
    "##Third training loop\n",
    "#input\n",
    "Env_pre.iter_critic = 2\n",
    "dropout_prob = 0.7\n",
    "\n",
    "Env_pre.tune_params[\"dropout_prob\"] = dropout_prob\n",
    "\n",
    "Env_pre.generator.change_dropout(dropout_prob)\n",
    "Env_pre.critic.change_dropout(dropout_prob)\n",
    "\n",
    "telapsed_summary_3 = Env_pre.tuneAndTrain(preTrained=False)\n",
    "\n",
    "##Save time stats\n",
    "dat_telapsed = pd.concat([telapsed_summary_1, telapsed_summary_2, telapsed_summary_3], axis=1)\n",
    "dat_telapsed.to_csv(Env_pre.PATH + '/Results/telapsed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4634e3-4a22-4d14-aba3-7fddb0c018c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5908c6-3ccf-4e0f-8107-f55b70dfa335",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'n_pre_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 159\u001b[0m\n\u001b[0;32m    156\u001b[0m Env_under\u001b[38;5;241m.\u001b[39mn_training_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(Env_under\u001b[38;5;241m.\u001b[39mpath_dat)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#number of records in file (excludes header)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_ID[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 159\u001b[0m     telapsed_summary \u001b[38;5;241m=\u001b[39m \u001b[43mEnv_under\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuneAndTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     telapsed_summary \u001b[38;5;241m=\u001b[39m Env_under\u001b[38;5;241m.\u001b[39mtuneAndTrain(preTrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\GAN_Scripts\\GAN_Tools.py:632\u001b[0m, in \u001b[0;36mEnvironment.tuneAndTrain\u001b[1;34m(self, preTrained)\u001b[0m\n\u001b[0;32m    628\u001b[0m max_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_loss_2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[0;32m    629\u001b[0m min_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_loss_2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    631\u001b[0m lr_1, n_epochs_1, lr_2, results_tuning_1, results_tuning_2 \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 632\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreTrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreTrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m results_tuning_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(results_tuning_1)\n\u001b[0;32m    635\u001b[0m results_tuning_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(results_tuning_2)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\GAN_Scripts\\GAN_Tools.py:493\u001b[0m, in \u001b[0;36mEnvironment.auto_tune\u001b[1;34m(self, max_epochs_1, max_loss_1, n_epochs_2, dropout_prob, seed, lr_1, lr_2, rate_save, diff_epochs, max_loss_2, min_loss_2, alpha_instab, preTrained)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lr_1), \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    492\u001b[0m     lr \u001b[38;5;241m=\u001b[39m lr_1[i]\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pre\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m118\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreTrained\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreTrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_prePars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_prePars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_record \u001b[38;5;241m=\u001b[39m Results(path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_results, saved_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    496\u001b[0m     iterator_tqdm \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, max_epochs_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m), desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_1 \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m  (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lr_1)) )\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\GAN_Scripts\\GAN_Tools.py:420\u001b[0m, in \u001b[0;36mEnvironment.load_pre\u001b[1;34m(self, dropout_prob, seed, preTrained, path_prePars)\u001b[0m\n\u001b[0;32m    418\u001b[0m flag_loadPars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preTrained:\n\u001b[1;32m--> 420\u001b[0m     id_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mn_pre_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mPretraining\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mn_pre_layers\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'n_pre_layers'"
     ]
    }
   ],
   "source": [
    "#input##########################\n",
    "PATH = config[\"PATH\"]\n",
    "\n",
    "config_re = config[\"retraining\"]\n",
    "###Which Data\n",
    "experiment_data = config[\"experiment_data\"]\n",
    "\n",
    "#%%\n",
    "################################\n",
    "##Check dir structure\n",
    "\n",
    "if experiment_data == 'metabolomics':\n",
    "    dirs = [\n",
    "        '/1a', '/1b', '/1c'\n",
    "        ]\n",
    "else:\n",
    "    dirs = [\n",
    "        '/1a', '/1b', '/1c',\n",
    "        '/2a', '/2b', '/2c',\n",
    "        '/3a', '/3b', '/3c',\n",
    "        '/4a', '/4b', '/4c',\n",
    "        '/5a', '/5b', '/5c',\n",
    "        '/6a', '/6b', '/6c',\n",
    "        '/7a', '/7b', '/7c',\n",
    "        '/8a', '/8b', '/8c',\n",
    "        '/9a', '/9b', '/9c',\n",
    "        '/1-Compare', '/2-Compare', '/3-Compare',\n",
    "        '/4-Compare', '/5-Compare', '/6-Compare', \n",
    "        '/7-Compare', '/8-Compare', '/9-Compare'\n",
    "        ]\n",
    "\n",
    "for path_ID in dirs:\n",
    "    #if not isdir(PATH+ path_ID):\n",
    "    #    mkdir(PATH+path_ID)\n",
    "    ##Check dir structure, and make sub-directories if not present\n",
    "    if not isdir(PATH+ path_ID+'/Results'):\n",
    "        mkdir(PATH+path_ID+'/Results')\n",
    "    if not isdir(PATH+path_ID+'/Results/External_Results'):\n",
    "        mkdir(PATH+path_ID+'/Results/External_Results')\n",
    "    if not isdir(PATH+path_ID+'/Results/Main_Results'):\n",
    "        mkdir(PATH+path_ID+'/Results/Main_Results')\n",
    "    if not isdir(PATH+path_ID+'/Results/Main_Results/underrep'):\n",
    "        mkdir(PATH+path_ID+'/Results/Main_Results/underrep')\n",
    "    if not isdir(PATH+path_ID+'/Results/External_Results/Saved_Pars'):\n",
    "        mkdir(PATH+path_ID+'/Results/External_Results/Saved_Pars')\n",
    "    if not isdir(PATH+path_ID+'/Results/Main_Results/underrep/Saved_Pars'):\n",
    "        mkdir(PATH+path_ID+'/Results/Main_Results/underrep/Saved_Pars')\n",
    "    if not isdir(PATH+path_ID+'/Results/Main_Results/overrep'):\n",
    "        mkdir(PATH+path_ID+'/Results/Main_Results/overrep')\n",
    "    if not isdir(PATH+path_ID+'/Results/Main_Results/overrep/Saved_Pars'):\n",
    "        mkdir(PATH+path_ID+'/Results/Main_Results/overrep/Saved_Pars')\n",
    "    if not isdir(PATH+path_ID+'/Data'):\n",
    "        mkdir(PATH+path_ID+'/Data')\n",
    "        print('WARNING: ENSURE DATA IS COPIED INTO THIS DIRECTORY')\n",
    "\n",
    "#%%\n",
    "\n",
    "func_optim_under = getattr(optim, config_re[\"func_optim\"][0])\n",
    "func_optim_over = getattr(optim, config_re[\"func_optim\"][1])\n",
    "\n",
    "for path_ID in dirs:\n",
    "\n",
    "    Env_under, Env_over = Environment(), Environment()\n",
    "    Env_under.device, Env_over.device = get_default_device(), get_default_device()\n",
    "    Env_under.PATH, Env_over.PATH = PATH, PATH\n",
    "\n",
    "    ##Input ################################\n",
    "    Env_under.n_features, Env_over.n_features = config_re[\"n_features\"][0], config_re[\"n_features\"]\n",
    "    Env_under.func_optim, Env_over.func_optim = func_optim_under, func_optim_over\n",
    "\n",
    "    Env_under.batch_size, Env_over.batch_size = config_re[\"batch_size\"][0], config_re[\"batch_size\"][1]\n",
    "    Env_under.iter_critic, Env_over.iter_critic = config_re[\"iter_critic\"][0], config_re[\"iter_critic\"][1]\n",
    "    Env_under.beta, Env_over.beta = config_re[\"beta\"][0], config_re[\"beta\"][1]\n",
    "    \n",
    "    dropout_prob = config_re[\"dropout_prob\"][0]\n",
    "\n",
    "    if path_ID[-1] == 'a':\n",
    "        Env_under.alpha, Env_over.alpha = 0, 0\n",
    "    elif path_ID[-1] == 'b':\n",
    "        Env_under.alpha, Env_over.alpha = 1, 0\n",
    "    elif path_ID[-1] == 'c':\n",
    "        Env_under.alpha, Env_over.alpha = 1, 1\n",
    "    elif path_ID[-1] == 'e':\n",
    "        Env_under.alpha, Env_over.alpha = 0, 0\n",
    "    else:\n",
    "        print('error')\n",
    "        break\n",
    "        \n",
    "    Env_under.tune_params = dict(\n",
    "        max_epochs_1=config_re[\"max_epochs_1\"][0], \n",
    "        max_loss_1=config_re[\"max_loss_1\"][0], \n",
    "        n_epochs_2=config_re[\"n_epochs_2\"][0], \n",
    "        dropout_prob=config_re[\"dropout_prob\"][0], \n",
    "        seed=config[\"random_seed\"], \n",
    "        lr_1 = config_re[\"lr_1\"][0],\n",
    "        lr_2 = config_re[\"lr_2\"][0],              \n",
    "        rate_save = config_re[\"rate_save\"][0], \n",
    "        diff_epochs = config_re[\"diff_epochs\"][0], \n",
    "        max_loss_2 = config_re[\"max_loss_2\"][0], \n",
    "        min_loss_2 = config_re[\"min_loss_2\"][0],\n",
    "        alpha_instab = config_re[\"alpha_instab\"][0],\n",
    "    )\n",
    "    Env_over.tune_params = dict(\n",
    "        max_epochs_1=config_re[\"max_epochs_1\"][1], \n",
    "        max_loss_1=config_re[\"max_loss_1\"][1], \n",
    "        n_epochs_2=config_re[\"n_epochs_2\"][1], \n",
    "        dropout_prob=config_re[\"dropout_prob\"][1], \n",
    "        seed=config[\"random_seed\"], \n",
    "        lr_1 = config_re[\"lr_1\"][1],\n",
    "        lr_2 = config_re[\"lr_2\"][1],              \n",
    "        rate_save = config_re[\"rate_save\"][1], \n",
    "        diff_epochs = config_re[\"diff_epochs\"][1], \n",
    "        max_loss_2 = config_re[\"max_loss_2\"][1], \n",
    "        min_loss_2 = config_re[\"min_loss_2\"][1],\n",
    "        alpha_instab = config_re[\"alpha_instab\"][1],\n",
    "    )\n",
    "    ######################################################\n",
    "    ##remove IDs and label\n",
    "    def prepare_dat(path_dir, file_name, n_cols_rem):\n",
    "        dat_temp = pd.read_csv(path_dir + '/' + file_name)\n",
    "        dat_temp = dat_temp.iloc[:, n_cols_rem:]\n",
    "        dat_temp.to_csv(path_dir + '/' + file_name[:-4] + '_inp.csv', index = False)\n",
    "\n",
    "    if experiment_data == 'microarray':\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_class1.csv', 2)\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_combo.csv', 2)\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_class2.csv', 2)\n",
    "    if experiment_data == 'simulation':\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_class1.csv', 0)\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_combo.csv', 1)\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_class2.csv', 0)\n",
    "    if experiment_data == 'metabolomics':\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_class1.csv', 2)\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_combo.csv', 2)\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_class2.csv', 2)\n",
    "\n",
    "\n",
    "    ################################################################################\n",
    "    ##UNDER RE-training loop\n",
    "    ##Prepare data\n",
    "    Env_under.path_dat = PATH + path_ID + '/Data/dat_real_combo_inp.csv'\n",
    "    Env_under.path_results = PATH + path_ID + '/Results/Main_Results/underrep'\n",
    "    Env_under.path_pars = Env_under.path_results + '/Saved_Pars'\n",
    "    \n",
    "    Env_under.results_record = Results(path = Env_under.path_results, saved_results = False)\n",
    "\n",
    "    ##transformer based on all data (Combo), due to limited available\n",
    "    Env_under.transformer = Env_under.get_scaler( (sum(1 for line in open(Env_under.path_dat)) - 1), '/real_transformer.pkl')\n",
    "\n",
    "\n",
    "    if experiment_data == 'microarray' or experiment_data == 'metabolomics':\n",
    "        Env_under.path_dat = PATH + path_ID + '/Data/dat_real_class1_inp.csv'\n",
    "    if experiment_data == 'simulation':\n",
    "        Env_under.path_dat = PATH + path_ID + '/Data/dat_real_class1.csv'\n",
    "\n",
    "    Env_under.n_training_samples = sum(1 for line in open(Env_under.path_dat)) - 1 #number of records in file (excludes header)\n",
    "    \n",
    "    Env_under.generator = GanComponent((Env_pre.n_features, \n",
    "                              Env_pre.init_weights, \n",
    "                              gen_struct[0], \n",
    "                              dropout_prob,\n",
    "                              \"generator\")\n",
    "    Env_under.critic = GanComponent((Env_pre.n_features, \n",
    "                              Env_pre.init_weights, \n",
    "                              critic_struct[0], \n",
    "                              dropout_prob,\n",
    "                              \"critic\"))\n",
    "    Env_under.generator.grow(gen_struct[1]).grow(gen_struct[2])\n",
    "    Env_under.critic.grow(critic_struct[1]).grow(critic_struct[2])\n",
    "    \n",
    "    if path_ID[-1] != 'e':\n",
    "        telapsed_summary = Env_under.tuneAndTrain()\n",
    "    else:\n",
    "        telapsed_summary = Env_under.tuneAndTrain(preTrained=False)\n",
    "    #save times\n",
    "    telapsed_summary.to_csv(Env_under.path_results + \"/time_training.csv\")\n",
    "\n",
    "    ################################################################################\n",
    "    ##OVER RE-training loop\n",
    "    ##Prepare data\n",
    "    if experiment_data == 'simulation':\n",
    "        Env_over.path_dat = Env_over.PATH + path_ID + '/Data/dat_real_class2.csv'\n",
    "    if experiment_data == 'microarray' or experiment_data == 'metabolomics':\n",
    "        Env_over.path_dat = Env_over.PATH + path_ID + '/Data/dat_real_class2_inp.csv'\n",
    "\n",
    "    Env_over.path_results = Env_over.PATH + path_ID + '/Results/Main_Results/overrep'\n",
    "    Env_over.path_pars = Env_over.path_results + '/Saved_Pars'\n",
    "\n",
    "    n_training_samples = sum(1 for line in open(Env_over.path_dat)) - 1 #number of records in file (excludes header)\n",
    "\n",
    "    Env_over.results_record = Results(path = Env_over.path_results, saved_results = False)\n",
    "\n",
    "    #load combo transformer\n",
    "    Env_over.transformer = joblib.load(Env_under.path_results + '/real_transformer.pkl')\n",
    "\n",
    "    Env_over.n_training_samples = sum(1 for line in open(Env_under.path_dat)) - 1 #number of records in file (excludes header)\n",
    "\n",
    "    Env_over.generator = GanComponent((Env_pre.n_features, \n",
    "                              Env_pre.init_weights, \n",
    "                              gen_struct[0], \n",
    "                              dropout_prob,\n",
    "                              \"generator\")\n",
    "    Env_over.critic = GanComponent((Env_pre.n_features, \n",
    "                              Env_pre.init_weights, \n",
    "                              critic_struct[0], \n",
    "                              dropout_prob,\n",
    "                              \"critic\"))\n",
    "    Env_over.generator.grow(gen_struct[1]).grow(gen_struct[2])\n",
    "    Env_over.critic.grow(critic_struct[1]).grow(critic_struct[2])\n",
    "                                       \n",
    "    if path_ID[-1] != 'e':\n",
    "        telapsed_summary = Env_under.tuneAndTrain(max_loss, min_loss)\n",
    "    else:\n",
    "        telapsed_summary = Env_under.tuneAndTrain(max_loss, min_loss, preTrained=False)\n",
    "    #save times\n",
    "    telapsed_summary.to_csv(Env_under.path_results + \"/time_training.csv\")\n",
    "\n",
    "    #############################################################################################################\n",
    "    #Load underrep GAN for validation\n",
    "    pre_generator = Generator(Env_under.n_features, \n",
    "                              Env_under.init_weights, \n",
    "                              config[\"gen_structure\"][0][0], \n",
    "                              dropout_prob)\n",
    "    pre_generator.grow(config[\"gen_structure\"][0][1])\n",
    "    pre_generator.grow(config[\"gen_structure\"][0][2])\n",
    "\n",
    "    pre_generator.load_pars(Env_under.path_pars, \n",
    "                            f\"{pre_generator.n_pre_layers}Retraining\", \n",
    "                            Env_under.device)\n",
    "    pre_generator.change_dropout(dropout_prob)\n",
    "\n",
    "    pre_generator.eval()\n",
    "    to_device(pre_generator, Env_under.device)\n",
    "\n",
    "\n",
    "    #Load overrep GAN for validation\n",
    "    pre_generator2 = Generator(Env_over.n_features, \n",
    "                               Env_under.init_weights, \n",
    "                               config[\"gen_structure\"][1][0], \n",
    "                               dropout_prob)\n",
    "    pre_generator2.grow(config[\"gen_structure\"][1][1])\n",
    "    pre_generator2.grow(config[\"gen_structure\"][1][2])\n",
    "\n",
    "    pre_generator2.load_pars(Env_over.path_pars, \n",
    "                             f\"{pre_generator2.n_pre_layers}Retraining\", \n",
    "                             Env_over.device)\n",
    "    pre_generator2.change_dropout(dropout_prob)\n",
    "\n",
    "    pre_generator2.eval()\n",
    "    to_device(pre_generator2, Env_over.device)\n",
    "\n",
    "    ##Validation\n",
    "    from GAN_Tools import classification_metrics\n",
    "\n",
    "    if experiment_data == 'microarray':\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_combo.csv', 1) #remove ID, keep label\n",
    "        prepare_dat(PATH + '/Data', 'dat_val.csv', 2) #remove obsolete col and ID\n",
    "    if experiment_data == 'simulation':\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_combo.csv', 0)\n",
    "        prepare_dat(PATH + '/Data', 'dat_val.csv', 0)\n",
    "    if experiment_data == 'metabolomics':\n",
    "        prepare_dat(PATH + path_ID + '/Data', 'dat_real_combo.csv', 1)\n",
    "        prepare_dat(PATH + '/Data', 'dat_val.csv', 1)\n",
    "\n",
    "    np.random.seed(120)\n",
    "    manual_seed(120)\n",
    "    random.seed(120)\n",
    "\n",
    "    #input##########################\n",
    "    if experiment_data == 'simulation':\n",
    "        path_dat_train = PATH + path_ID + '/Data/dat_real_combo_inp.csv'\n",
    "        path_dat_val = PATH + '/Data/dat_val_inp.csv'\n",
    "    if experiment_data == 'microarray' or experiment_data == 'metabolomics':\n",
    "        path_dat_train = PATH + path_ID + '/Data/dat_real_combo_inp.csv'\n",
    "        path_dat_val = PATH + '/Data/dat_val_inp.csv'\n",
    "    ################################\n",
    "\n",
    "    path_transformer = PATH + path_ID + '/Results/Main_Results/underrep' + '/real_transformer.pkl'\n",
    "\n",
    "\n",
    "    #the case label must be 1st alphabetically due to functionality of labelEncoder\n",
    "    classification_metrics(path_dat_train, path_dat_val, pre_generator, path_transformer,\n",
    "                           Env_under.n_features, Env_under.device,\n",
    "                           PATH + path_ID,\n",
    "                           pre_generator2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
